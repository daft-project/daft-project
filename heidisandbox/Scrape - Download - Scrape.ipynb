{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daft Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get individual rental ad  URLs\n",
    "Pagination is done using the 'offset' property in the search results URL, so we can use that browse through the results pages.  \n",
    "Daft displays 20 results per page, hence the value of '20' in this line:\n",
    "       `for offset in range(0, number_of_adds, 20):`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of Dublin rental ads: 300\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "daftresults_urlroot = 'http://www.daft.ie/dublin/apartments-for-rent/?s%5Bignored_agents%5D%5B0%5D=5732&s%5Bignored_agents%5D%5B1%5D=428&s%5Bignored_agents%5D%5B2%5D=1551&s%5Bsort_by%5D=date&s%5Bsort_type%5D=d&offset='\n",
    "allAdUrls = []\n",
    "number_of_adds = 300\n",
    "\n",
    "def getAdUrls(pageresults):\n",
    "    \n",
    "    adURLs = []\n",
    "    for result in pageresults:\n",
    "        adURLs.append(\"http://www.daft.ie\" + result.a[\"href\"])\n",
    "    return adURLs\n",
    "\n",
    "for offset in range(0, number_of_adds, 20):\n",
    "    results_html = urllib.request.urlopen(daftresults_urlroot + str(offset)).read()\n",
    "    soup = BeautifulSoup(results_html, \"html5lib\")\n",
    "    results = soup.find_all(\"div\", class_=\"search_result_title_box\")\n",
    "    allAdUrls = allAdUrls + getAdUrls(results)\n",
    "\n",
    "#print(allAdUrls)\n",
    "print('Current number of Dublin rental ads: ' + str(len(allAdUrls)))\n",
    "number_of_adds = len(allAdUrls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Download individual Ad pages\n",
    "\n",
    "This section loops through the list of individual rental ad URLs, and downloads them into a 'daftpages' directory. \n",
    "\n",
    "#### Skip if you download and extract the zipped/tared archive instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rental Ad URLs are now in this array: allAdUrls\n",
    "# Loop through and download\n",
    "\n",
    "for idx,adUrl in enumerate(allAdUrls):\n",
    "    filename = adUrl.split('/')[-2]\n",
    "    urllib.request.urlretrieve(adUrl, 'daftpages/'+ filename + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip up pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "current_date = datetime.datetime.now().isoformat()\n",
    "tar_file_name = 'daftpages_' + current_date + '.tar'\n",
    "source_dir = 'daftpages/'\n",
    "with tarfile.open(tar_file_name, \"w:gz\") as tar:\n",
    "    tar.add(source_dir, arcname=os.path.basename(source_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue reading in page daftpages/26-marlborough-street-dublin-1-dublin-1-dublin-1774504.html. Skipping this Ad.\n",
      "issue reading in page daftpages/cathedral-court-dublin-2-dublin-1771875.html. Skipping this Ad.\n",
      "issue reading in page daftpages/city-gate-st-augustines-st-dublin-8-dublin-1771830.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_108.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_167.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_170.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_173.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_180.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_181.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_182.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_25.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_257.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_351.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_398.html. Skipping this Ad.\n",
      "issue reading in page daftpages/daft_ad_503.html. Skipping this Ad.\n",
      "issue reading in page daftpages/marine-court-crofton-road-dunlaoghaire-dun-laoghaire-dublin-1773045.html. Skipping this Ad.\n",
      "issue reading in page daftpages/newcastle-boulevard-newcastle-dublin-1772908.html. Skipping this Ad.\n",
      "issue reading in page daftpages/saint-mobhi-boithrn-glasnevin-dublin-1774257.html. Skipping this Ad.\n",
      "issue reading in page daftpages/the-plaza-swords-dublin-1772641.html. Skipping this Ad.\n",
      "issue reading in page daftpages/trinity-square-townsend-street-dublin-2-dublin-1772442.html. Skipping this Ad.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "num_of_rows = number_of_adds\n",
    "data_csv = 'data/scraped_data.csv'\n",
    "all_orig_field_names = [\n",
    "    'property_id',\n",
    "    'property_category',\n",
    "    'property_title',\n",
    "    'property_type',\n",
    "    'seller_name',\n",
    "    'seller_id',\n",
    "    'seller_type',\n",
    "    'open_viewing',\n",
    "    'no_of_photos',\n",
    "    'available_from',\n",
    "    'lease_units',\n",
    "    'available_for',    \n",
    "    'area',\n",
    "    'county',\n",
    "    'latitude',\n",
    "    'longitude',    \n",
    "    'furnished',\n",
    "    'bathrooms',   \n",
    "    'beds',   \n",
    "    'facility',    \n",
    "    'environment',\n",
    "    'published_date',\n",
    "    'page_name',\n",
    "    'platform',\n",
    "    'currency',\n",
    "    'price_frequency',\n",
    "    'price'\n",
    "]\n",
    "all_facilities=[\n",
    "    'Parking', \n",
    "    'Cable Television', \n",
    "    'Dryer', \n",
    "    'Garden / Patio / Balcony', \n",
    "    'Washing Machine', \n",
    "    'Serviced Property', \n",
    "    'Pets Allowed', \n",
    "    'Wheelchair Access', \n",
    "    'Central Heating', \n",
    "    'Microwave', \n",
    "    'Smoking', \n",
    "    'Dishwasher', \n",
    "    'House Alarm', \n",
    "    'Internet'\n",
    "]\n",
    "\n",
    "with open(data_csv, 'w') as csvfile:\n",
    "    for idx,daft_filename in enumerate(os.listdir('daftpages/')):\n",
    "        try:\n",
    "            adpage_html = open('daftpages/' + daft_filename).read()\n",
    "            soup = BeautifulSoup(adpage_html, \"html5lib\")\n",
    "        except:\n",
    "            # seems like some pages have encoding issues?\n",
    "            print('issue reading in page daftpages/' + daft_filename + '. Skipping this Ad.')\n",
    "            continue\n",
    "\n",
    "        #print(soup)\n",
    "        # There is a handy javascrupt json dictionary on those daft pages, listing key features of the add\n",
    "        # To get this data, find all script tags, then get the contents of the 10ths tag found (seems to be the 10th.\n",
    "        # Now, this seems to be a bit brittle, need to find a way to target this better than just hope it'll always be \n",
    "        # the 10th script tag on the page; But maybe for now it's enough)\n",
    "        scriptdata = soup.find_all('script', type='text/javascript')    \n",
    "        trackingparams = scriptdata[10].get_text()\n",
    "        trackingparams = trackingparams.replace('\\u20ac','')\n",
    "\n",
    "        try:\n",
    "            feature_str = \"{\" + str(re.search('\\\\{(.+?)\\\\}', trackingparams).group(1)) + \"}\"\n",
    "        except AttributeError:\n",
    "            feature_str = \"{}\"\n",
    "    \n",
    "        ad_data = json.loads(feature_str)  \n",
    "        \n",
    "        field_names = ad_data.keys()\n",
    "        \n",
    "        facilities = ad_data['facility'].split(',')\n",
    "        facilties_dict = dict.fromkeys(all_facilities)\n",
    "        for facility in facilities:\n",
    "            if facility in all_facilities:\n",
    "                facilties_dict[facility] = True\n",
    " \n",
    "\n",
    "        # check for missing fields (mostly seller_id and seller_name), and add them with empty vals if required\n",
    "        missing_fiels = set(all_orig_field_names) - set(field_names)\n",
    "        for missing in missing_fiels:\n",
    "            ad_data[missing] = \"\"\n",
    "        \n",
    "        ad_data.update(facilties_dict)\n",
    "        \n",
    "        all_field_names = all_orig_field_names + all_facilities\n",
    "        \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=all_field_names)\n",
    "        if idx == 0: \n",
    "            writer.writeheader()\n",
    "        writer.writerow(ad_data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create Pandas Dataframe from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_title</th>\n",
       "      <th>property_type</th>\n",
       "      <th>seller_name</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>seller_type</th>\n",
       "      <th>open_viewing</th>\n",
       "      <th>no_of_photos</th>\n",
       "      <th>available_from</th>\n",
       "      <th>lease_units</th>\n",
       "      <th>...</th>\n",
       "      <th>Washing Machine</th>\n",
       "      <th>Serviced Property</th>\n",
       "      <th>Pets Allowed</th>\n",
       "      <th>Wheelchair Access</th>\n",
       "      <th>Central Heating</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>House Alarm</th>\n",
       "      <th>Internet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1772670</td>\n",
       "      <td>1 BED, Tallaght Cross West, Tallaght, Dublin 24</td>\n",
       "      <td>apartment</td>\n",
       "      <td>IRES</td>\n",
       "      <td>9871.0</td>\n",
       "      <td>agent</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>months</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1773305</td>\n",
       "      <td>1 Palace Street, Dublin 2, Dublin 2</td>\n",
       "      <td>apartment</td>\n",
       "      <td>Herbert Property Services</td>\n",
       "      <td>7549.0</td>\n",
       "      <td>agent</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-09-15</td>\n",
       "      <td>months</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1773577</td>\n",
       "      <td>10 Clarinda House, Clarinda Park West, Dun Lao...</td>\n",
       "      <td>apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>private</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>months</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1772865</td>\n",
       "      <td>109 Geraldstown Wood, Santry, Dublin 9</td>\n",
       "      <td>apartment</td>\n",
       "      <td>KELLY BRADSHAW DALTON</td>\n",
       "      <td>11.0</td>\n",
       "      <td>agent</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-09-13</td>\n",
       "      <td>months</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1771138</td>\n",
       "      <td>11 saunders house, spencer dock, Dublin 1, Dub...</td>\n",
       "      <td>apartment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>private</td>\n",
       "      <td>no</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-09-16</td>\n",
       "      <td>months</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id                                     property_title  \\\n",
       "0      1772670    1 BED, Tallaght Cross West, Tallaght, Dublin 24   \n",
       "1      1773305                1 Palace Street, Dublin 2, Dublin 2   \n",
       "2      1773577  10 Clarinda House, Clarinda Park West, Dun Lao...   \n",
       "3      1772865             109 Geraldstown Wood, Santry, Dublin 9   \n",
       "4      1771138  11 saunders house, spencer dock, Dublin 1, Dub...   \n",
       "\n",
       "  property_type                seller_name  seller_id seller_type  \\\n",
       "0     apartment                       IRES     9871.0       agent   \n",
       "1     apartment  Herbert Property Services     7549.0       agent   \n",
       "2     apartment                        NaN        NaN     private   \n",
       "3     apartment      KELLY BRADSHAW DALTON       11.0       agent   \n",
       "4     apartment                        NaN        NaN     private   \n",
       "\n",
       "  open_viewing  no_of_photos available_from lease_units   ...     \\\n",
       "0           no             3     2017-10-01      months   ...      \n",
       "1           no             6     2017-09-15      months   ...      \n",
       "2           no             8     2017-09-18      months   ...      \n",
       "3          yes             6     2017-09-13      months   ...      \n",
       "4           no            10     2017-09-16      months   ...      \n",
       "\n",
       "   Washing Machine Serviced Property Pets Allowed  Wheelchair Access  \\\n",
       "0             True               NaN          NaN                NaN   \n",
       "1             True               NaN          NaN                NaN   \n",
       "2             True               NaN          NaN                NaN   \n",
       "3             True               NaN          NaN                NaN   \n",
       "4             True               NaN          NaN                NaN   \n",
       "\n",
       "   Central Heating Microwave  Smoking  Dishwasher House Alarm Internet  \n",
       "0             True      True      NaN        True         NaN      NaN  \n",
       "1             True      True      NaN         NaN         NaN     True  \n",
       "2             True      True      NaN         NaN         NaN     True  \n",
       "3             True      True      NaN        True         NaN      NaN  \n",
       "4              NaN       NaN      NaN         NaN         NaN      NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_csv = 'data/scraped_data.csv'\n",
    "df = pd.read_csv(data_csv)\n",
    "\n",
    "#drop some not very useful columns\n",
    "df = df.drop('environment', 1)\n",
    "df = df.drop('page_name', 1)\n",
    "df = df.drop('platform', 1)\n",
    "df = df.drop('property_category', 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
