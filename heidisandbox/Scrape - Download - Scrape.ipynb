{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daft Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get individual rental ad  URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current number of Dublin rental ads: 639\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "daftresults_urlroot = 'http://www.daft.ie/dublin/apartments-for-rent/?s%5Bignored_agents%5D%5B0%5D=5732&s%5Bignored_agents%5D%5B1%5D=428&s%5Bignored_agents%5D%5B2%5D=1551&offset='\n",
    "allAdUrls = []\n",
    "number_of_adds = 700\n",
    "\n",
    "def getAdUrls(pageresults):\n",
    "    \n",
    "    adURLs = []\n",
    "    for result in pageresults:\n",
    "        adURLs.append(\"http://www.daft.ie\" + result.a[\"href\"])\n",
    "    return adURLs\n",
    "\n",
    "for offset in range(0, number_of_adds, 20):\n",
    "    results_html = urllib.request.urlopen(daftresults_urlroot + str(offset)).read()\n",
    "    soup = BeautifulSoup(results_html, \"html5lib\")\n",
    "    results = soup.find_all(\"div\", class_=\"search_result_title_box\")\n",
    "    allAdUrls = allAdUrls + getAdUrls(results)\n",
    "\n",
    "#print(allAdUrls)\n",
    "print('Current number of Dublin rental ads: ' + str(len(allAdUrls)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Download individual Ad pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rental Ad URLs are now in this array: allAdUrls\n",
    "# Loop through and download\n",
    "\n",
    "for idx,adUrl in enumerate(allAdUrls):\n",
    "    urllib.request.urlretrieve(adUrl, 'daftpages/daft_ad_' + str(idx) + '.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip up pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "source_dir = 'daftpages/'\n",
    "with tarfile.open('daftpages.tar', \"w:gz\") as tar:\n",
    "    tar.add(source_dir, arcname=os.path.basename(source_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
